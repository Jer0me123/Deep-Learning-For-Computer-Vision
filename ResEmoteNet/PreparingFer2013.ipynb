{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the FER2013 dataset\n",
    "\n",
    "Note: Mappings are converting to be common with all other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "   emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
      "\n",
      "Testing Set:\n",
      "       emotion                                             pixels       Usage\n",
      "28709        0  254 254 254 254 254 249 255 160 2 58 53 70 77 ...  PublicTest\n",
      "28710        1  156 184 198 202 204 207 210 212 213 214 215 21...  PublicTest\n",
      "28711        4  69 118 61 60 96 121 103 87 103 88 70 90 115 12...  PublicTest\n",
      "28712        6  205 203 236 157 83 158 120 116 94 86 155 180 2...  PublicTest\n",
      "28713        3  87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...  PublicTest\n",
      "\n",
      "Validation Set:\n",
      "       emotion                                             pixels        Usage\n",
      "32298        0  170 118 101 88 88 75 78 82 66 74 68 59 63 64 6...  PrivateTest\n",
      "32299        5  7 5 8 6 7 3 2 6 5 4 4 5 7 5 5 5 6 7 7 7 10 10 ...  PrivateTest\n",
      "32300        6  232 240 241 239 237 235 246 117 24 24 22 13 12...  PrivateTest\n",
      "32301        4  200 197 149 139 156 89 111 58 62 95 113 117 11...  PrivateTest\n",
      "32302        2  40 28 33 56 45 33 31 78 152 194 200 186 196 20...  PrivateTest\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('FER/fer2013.csv')\n",
    "\n",
    "# Filter the dataset into three sets based on the value in 'Usage'\n",
    "training_set = df[df['Usage'] == 'Training']\n",
    "testing_set = df[df['Usage'] == 'PublicTest']\n",
    "validation_set = df[df['Usage'] == 'PrivateTest']\n",
    "\n",
    "# This will be the emotion mapping used throughout the project (for all datasets)\n",
    "universal_emotion_mapping = {'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3, 'Sad': 4, 'Surprise': 5, 'Neutral': 6}\n",
    "\n",
    "# Dataset specific emotion mapping (The mappings will be converted to the universal mapping for consistency)\n",
    "emotion_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "\n",
    "# Display the first few rows of each set\n",
    "print(\"Training Set:\")\n",
    "# Correctly mapping the labels to the universal emotion mapping\n",
    "training_set.loc[:, 'emotion'] = training_set['emotion'].map(emotion_mapping).map(universal_emotion_mapping)\n",
    "print(training_set.head())\n",
    "\n",
    "print(\"\\nTesting Set:\")\n",
    "# Correctly mapping the labels to the universal emotion mapping\n",
    "testing_set.loc[:, 'emotion'] = testing_set['emotion'].map(emotion_mapping).map(universal_emotion_mapping)\n",
    "print(testing_set.head())\n",
    "\n",
    "print(\"\\nValidation Set:\")\n",
    "# Correctly mapping the labels to the universal emotion mapping\n",
    "validation_set.loc[:, 'emotion'] = validation_set['emotion'].map(emotion_mapping).map(universal_emotion_mapping)\n",
    "print(validation_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the images according to their use case \n",
    "\n",
    "Note: Images are named as follows {test/train/validation}\\_{index}\\_{emotion_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "destination_directory = 'FER_ResEmoteNet'\n",
    "universal_emotion_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(destination_directory+'/train', exist_ok=True)\n",
    "os.makedirs(destination_directory+'/test', exist_ok=True)\n",
    "os.makedirs(destination_directory+'/validation', exist_ok=True)\n",
    "\n",
    "def save_images(dataset, set_name):\n",
    "    for index, row in dataset.iterrows():\n",
    "        emotion_label = universal_emotion_mapping[row['emotion']]\n",
    "        image_data = row['pixels']\n",
    "        image_pixels = np.fromstring(image_data, sep=' ').astype(int)\n",
    "        image_pixels = image_pixels.reshape(48, 48)\n",
    "        \n",
    "        # Create an image from the pixel data\n",
    "        image = Image.fromarray(image_pixels.astype('uint8'), 'L')\n",
    "        \n",
    "        # Save the image to the appropriate directory\n",
    "        image.save(f'{destination_directory}/{set_name}/{set_name}_{index}_{emotion_label.lower()}.jpg')\n",
    "\n",
    "# Save images for each set\n",
    "save_images(training_set, 'train')\n",
    "save_images(testing_set, 'test')\n",
    "save_images(validation_set, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenting the data in the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image augmentation completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "\n",
    "dataset_path = os.path.join(destination_directory, 'train')\n",
    "target_num_images = 1000\n",
    "\n",
    "def augment_image(image):\n",
    "    \"\"\"Apply random augmentations to an image.\"\"\"\n",
    "    augmentations = [\n",
    "        lambda x: x.rotate(random.randint(-30, 30)),\n",
    "        lambda x: ImageOps.mirror(x),\n",
    "        lambda x: ImageOps.crop(x, border=random.randint(0, 10)),\n",
    "    ]\n",
    "    augmentation = random.choice(augmentations)\n",
    "    return augmentation(image)\n",
    "\n",
    "# Group images by emotion\n",
    "images_by_emotion = {}\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if filename.endswith(('.jpg', '.png')):\n",
    "        emotion = filename.split('_')[-1].split('.')[0]\n",
    "        # print(emotion)\n",
    "        if emotion not in images_by_emotion:\n",
    "            images_by_emotion[emotion] = []\n",
    "        images_by_emotion[emotion].append(filename)\n",
    "\n",
    "# Augment images for each emotion\n",
    "for emotion, images in images_by_emotion.items():\n",
    "    num_images = len(images)\n",
    "    \n",
    "    if num_images < target_num_images:\n",
    "        for i in range(target_num_images - num_images):\n",
    "            original_image_path = os.path.join(dataset_path, images[i % num_images])\n",
    "            with Image.open(original_image_path) as img:\n",
    "                augmented_image = augment_image(img)\n",
    "                new_image_name = f'train_augmented_{num_images + i + 1}_{emotion}.jpg'\n",
    "                augmented_image.save(os.path.join(dataset_path, new_image_name))\n",
    "\n",
    "print(\"Image augmentation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extension = 'jpg'\n",
    "\n",
    "universal_emotion_mapping = {'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3, 'Sad': 4, 'Surprise': 5, 'Neutral': 6}\n",
    "\n",
    "folder_mapping = {'test': 'test', 'train': 'train', 'validation': 'val'}\n",
    "\n",
    "# Iterate over the folders (test, train, validation)\n",
    "for folder in ['test', 'train', 'validation']:\n",
    "    folder_path = os.path.join(destination_directory, folder)\n",
    "\n",
    "    image_data = []\n",
    "\n",
    "    # Make sure the name of the file is partition_iteration_emotion.jpg or .png\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(file_extension):  \n",
    "            label_name = filename.split('_')[-1].split('.')[0]\n",
    "            label_value = universal_emotion_mapping.get(label_name.capitalize())\n",
    "            if label_value is not None:  \n",
    "                image_data.append([filename, label_value])\n",
    "\n",
    "    df = pd.DataFrame(image_data, columns=[\"ImageName\", \"Label\"])\n",
    "\n",
    "    csv_file_path = os.path.join(folder_path, 'labels.csv')\n",
    "\n",
    "    df.to_csv(csv_file_path, index=False, header=['filename', 'label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
