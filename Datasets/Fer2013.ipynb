{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The FER labels already align with the universal emotion labels\n",
    "# universal_emotion_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "FER_Label_Mapping = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise', 6:'Neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(dataset, base_dir, split_name, target_dir):\n",
    "    \"\"\"\n",
    "    Save images and create labels CSV for a dataset\n",
    "    \n",
    "    Parameters:\n",
    "    dataset (DataFrame): The dataset containing image data\n",
    "    split_name (str): Prefix for filenames (train/val/test)\n",
    "    target_dir (str): Subdirectory to save images and CSV\n",
    "    \"\"\"\n",
    "    label_data = []\n",
    "    \n",
    "    for idx, (_, row) in enumerate(dataset.iterrows()):\n",
    "        # Process pixels\n",
    "        pixels = np.array(list(map(int, row['pixels'].split())), dtype=np.uint8)\n",
    "        img_array = pixels.reshape(48, 48)\n",
    "        img = Image.fromarray(img_array)\n",
    "        \n",
    "        # Create filename components\n",
    "        emotion_label = row['emotion']\n",
    "        filename = f\"{split_name}_{idx}_{FER_Label_Mapping[emotion_label]}.png\"\n",
    "        \n",
    "        # Save image\n",
    "        img.save(os.path.join(base_dir, target_dir, filename))\n",
    "        \n",
    "        # Store label information\n",
    "        label_data.append({'filename': filename, 'label': emotion_label})\n",
    "    \n",
    "    # Create and save labels DataFrame\n",
    "    labels_df = pd.DataFrame(label_data)\n",
    "    labels_df.to_csv(os.path.join(base_dir, target_dir, 'labels.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images_to_label_subdirectories(base_dir):\n",
    "    \"\"\"\n",
    "    For each subdirectory (test, train, validation) in base_dir,\n",
    "    copy images into subdirectories based on their label, extracted from the filename.\n",
    "    \n",
    "    Expected filename format: {usecase}_{index}_{label}.{ext}\n",
    "    \"\"\"\n",
    "    # Define the usage folders.\n",
    "    usage_dirs = ['train', 'test', 'validation']\n",
    "    \n",
    "    for usage in usage_dirs:\n",
    "        usage_path = os.path.join(base_dir, usage)\n",
    "        if not os.path.isdir(usage_path):\n",
    "            print(f\"Directory {usage_path} does not exist. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Process each file in the usage folder.\n",
    "        for filename in os.listdir(usage_path):\n",
    "            file_path = os.path.join(usage_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                # Parse the filename. We expect at least 3 parts separated by '_'\n",
    "                parts = filename.split('_')\n",
    "                if len(parts) < 3:\n",
    "                    print(f\"Filename {filename} does not match expected format. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # The label is assumed to be the last part, with the file extension removed.\n",
    "                label_with_ext = parts[-1]\n",
    "                label, _ = os.path.splitext(label_with_ext)\n",
    "                \n",
    "                # Create the label subdirectory if it doesn't exist.\n",
    "                label_dir = os.path.join(usage_path, label)\n",
    "                os.makedirs(label_dir, exist_ok=True)\n",
    "                \n",
    "                # Copy the image into the label subdirectory.\n",
    "                destination_file_path = os.path.join(label_dir, filename)\n",
    "                shutil.copy2(file_path, destination_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename labels.csv does not match expected format. Skipping.\n",
      "Filename labels.csv does not match expected format. Skipping.\n",
      "Filename labels.csv does not match expected format. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('FER/fer2013.csv')\n",
    "\n",
    "# Define base directory structure\n",
    "base_directory = 'FER_Structured'\n",
    "os.makedirs(base_directory, exist_ok=True)\n",
    "\n",
    "# Create subdirectories\n",
    "for folder in ['train', 'validation', 'test']:\n",
    "    os.makedirs(os.path.join(base_directory, folder), exist_ok=True)\n",
    "\n",
    "# Filter the dataset into three sets based on the value in 'Usage'\n",
    "training_set = df[df['Usage'] == 'Training']\n",
    "validation_set = df[df['Usage'] == 'PublicTest']\n",
    "testing_set = df[df['Usage'] == 'PrivateTest']\n",
    "\n",
    "# Save all sets with images and labels\n",
    "save_images(training_set, base_directory, \"train\", \"train\")\n",
    "save_images(validation_set, base_directory, \"val\", \"validation\")\n",
    "save_images(testing_set, base_directory, \"test\", \"test\")\n",
    "\n",
    "copy_images_to_label_subdirectories(base_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the FER2013 dataset\n",
    "\n",
    "Note: Mappings are converting to be common with all other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "   emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
      "\n",
      "Testing Set:\n",
      "       emotion                                             pixels       Usage\n",
      "28709        0  254 254 254 254 254 249 255 160 2 58 53 70 77 ...  PublicTest\n",
      "28710        1  156 184 198 202 204 207 210 212 213 214 215 21...  PublicTest\n",
      "28711        4  69 118 61 60 96 121 103 87 103 88 70 90 115 12...  PublicTest\n",
      "28712        6  205 203 236 157 83 158 120 116 94 86 155 180 2...  PublicTest\n",
      "28713        3  87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...  PublicTest\n",
      "\n",
      "Validation Set:\n",
      "       emotion                                             pixels        Usage\n",
      "32298        0  170 118 101 88 88 75 78 82 66 74 68 59 63 64 6...  PrivateTest\n",
      "32299        5  7 5 8 6 7 3 2 6 5 4 4 5 7 5 5 5 6 7 7 7 10 10 ...  PrivateTest\n",
      "32300        6  232 240 241 239 237 235 246 117 24 24 22 13 12...  PrivateTest\n",
      "32301        4  200 197 149 139 156 89 111 58 62 95 113 117 11...  PrivateTest\n",
      "32302        2  40 28 33 56 45 33 31 78 152 194 200 186 196 20...  PrivateTest\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Read the CSV file\n",
    "# df = pd.read_csv('FER/fer2013.csv')\n",
    "\n",
    "# # Filter the dataset into three sets based on the value in 'Usage'\n",
    "# training_set = df[df['Usage'] == 'Training']\n",
    "# validation_set = df[df['Usage'] == 'PublicTest']\n",
    "# testing_set = df[df['Usage'] == 'PrivateTest']\n",
    "\n",
    "# # This will be the emotion mapping used throughout the project (for all datasets)\n",
    "# universal_emotion_mapping = {'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3, 'Sad': 4, 'Surprise': 5, 'Neutral': 6}\n",
    "\n",
    "# # Dataset specific emotion mapping (The mappings will be converted to the universal mapping for consistency)\n",
    "# emotion_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "\n",
    "# # Display the first few rows of each set\n",
    "# print(\"Training Set:\")\n",
    "# # Correctly mapping the labels to the universal emotion mapping\n",
    "# training_set.loc[:, 'emotion'] = training_set['emotion'].map(emotion_mapping).map(universal_emotion_mapping)\n",
    "# print(training_set.head())\n",
    "\n",
    "# print(\"\\nTesting Set:\")\n",
    "# # Correctly mapping the labels to the universal emotion mapping\n",
    "# testing_set.loc[:, 'emotion'] = testing_set['emotion'].map(emotion_mapping).map(universal_emotion_mapping)\n",
    "# print(testing_set.head())\n",
    "\n",
    "# print(\"\\nValidation Set:\")\n",
    "# # Correctly mapping the labels to the universal emotion mapping\n",
    "# validation_set.loc[:, 'emotion'] = validation_set['emotion'].map(emotion_mapping).map(universal_emotion_mapping)\n",
    "# print(validation_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the images according to their use case \n",
    "\n",
    "Note: Images are named as follows {test/train/validation}\\_{index}\\_{emotion_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# destination_directory = 'FER_ResEmoteNet'\n",
    "# universal_emotion_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "\n",
    "# # Create directories if they don't exist\n",
    "# os.makedirs(destination_directory+'/train', exist_ok=True)\n",
    "# os.makedirs(destination_directory+'/test', exist_ok=True)\n",
    "# os.makedirs(destination_directory+'/validation', exist_ok=True)\n",
    "\n",
    "# def save_images(dataset, set_name):\n",
    "#     for index, row in dataset.iterrows():\n",
    "#         emotion_label = universal_emotion_mapping[row['emotion']]\n",
    "#         image_data = row['pixels']\n",
    "#         image_pixels = np.fromstring(image_data, sep=' ').astype(int)\n",
    "#         image_pixels = image_pixels.reshape(48, 48)\n",
    "        \n",
    "#         # Create an image from the pixel data\n",
    "#         image = Image.fromarray(image_pixels.astype('uint8'), 'L')\n",
    "        \n",
    "#         # Save the image to the appropriate directory\n",
    "#         image.save(f'{destination_directory}/{set_name}/{set_name}_{index}_{emotion_label.lower()}.jpg')\n",
    "\n",
    "# # Save images for each set\n",
    "# save_images(training_set, 'train')\n",
    "# save_images(testing_set, 'test')\n",
    "# save_images(validation_set, 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenting the data in the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image augmentation completed.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from PIL import Image, ImageOps\n",
    "# import random\n",
    "\n",
    "# dataset_path = os.path.join(destination_directory, 'train')\n",
    "# target_num_images = 1000\n",
    "\n",
    "# def augment_image(image):\n",
    "#     \"\"\"Apply random augmentations to an image.\"\"\"\n",
    "#     augmentations = [\n",
    "#         lambda x: x.rotate(random.randint(-30, 30)),\n",
    "#         lambda x: ImageOps.mirror(x),\n",
    "#         lambda x: ImageOps.crop(x, border=random.randint(0, 10)),\n",
    "#     ]\n",
    "#     augmentation = random.choice(augmentations)\n",
    "#     return augmentation(image)\n",
    "\n",
    "# # Group images by emotion\n",
    "# images_by_emotion = {}\n",
    "# for filename in os.listdir(dataset_path):\n",
    "#     if filename.endswith(('.jpg', '.png')):\n",
    "#         emotion = filename.split('_')[-1].split('.')[0]\n",
    "#         # print(emotion)\n",
    "#         if emotion not in images_by_emotion:\n",
    "#             images_by_emotion[emotion] = []\n",
    "#         images_by_emotion[emotion].append(filename)\n",
    "\n",
    "# # Augment images for each emotion\n",
    "# for emotion, images in images_by_emotion.items():\n",
    "#     num_images = len(images)\n",
    "    \n",
    "#     if num_images < target_num_images:\n",
    "#         for i in range(target_num_images - num_images):\n",
    "#             original_image_path = os.path.join(dataset_path, images[i % num_images])\n",
    "#             with Image.open(original_image_path) as img:\n",
    "#                 augmented_image = augment_image(img)\n",
    "#                 new_image_name = f'train_augmented_{num_images + i + 1}_{emotion}.jpg'\n",
    "#                 augmented_image.save(os.path.join(dataset_path, new_image_name))\n",
    "\n",
    "# print(\"Image augmentation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_extension = 'jpg'\n",
    "\n",
    "# universal_emotion_mapping = {'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3, 'Sad': 4, 'Surprise': 5, 'Neutral': 6}\n",
    "\n",
    "# folder_mapping = {'test': 'test', 'train': 'train', 'validation': 'val'}\n",
    "\n",
    "# # Iterate over the folders (test, train, validation)\n",
    "# for folder in ['test', 'train', 'validation']:\n",
    "#     folder_path = os.path.join(destination_directory, folder)\n",
    "\n",
    "#     image_data = []\n",
    "\n",
    "#     # Make sure the name of the file is partition_iteration_emotion.jpg or .png\n",
    "#     for filename in os.listdir(folder_path):\n",
    "#         if filename.endswith(file_extension):  \n",
    "#             label_name = filename.split('_')[-1].split('.')[0]\n",
    "#             label_value = universal_emotion_mapping.get(label_name.capitalize())\n",
    "#             if label_value is not None:  \n",
    "#                 image_data.append([filename, label_value])\n",
    "\n",
    "#     df = pd.DataFrame(image_data, columns=[\"ImageName\", \"Label\"])\n",
    "\n",
    "#     csv_file_path = os.path.join(folder_path, 'labels.csv')\n",
    "\n",
    "#     df.to_csv(csv_file_path, index=False, header=['filename', 'label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
