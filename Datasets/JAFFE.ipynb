{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAFFE Dataset\n",
    "\n",
    "Download the dataset from the link below and then run the code to foramt it according to the requirements of the models. \n",
    "\n",
    "Additionally, run the FaceAlignment.ipynb to align the images such that features are consistent across all images.\n",
    "\n",
    "**Dataset Link:** https://zenodo.org/records/14974867"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The JAFFE dataset comes with a **A_README_FIRST.txt** file or similar. This file contains the image mappings in the strucutre below. \n",
    "This needs to be manually copied and pasted into another file named **mapping.csv** in the same directory prior to running the code below. \n",
    "\n",
    "\n",
    "**Old Format:**\n",
    "\n",
    "<p># HAP SAD SUR ANG DIS FEA PIC <br>\n",
    "-------------------------------------------------------------- <br>\n",
    "1 2.87 2.52 2.10 1.97 1.97 2.06 KM-NE1 <br>\n",
    "2 2.87 2.42 1.58 1.84 1.77 1.77 KM-NE2 <br>\n",
    "3 2.50 2.10 1.70 1.50 1.73 1.53 KM-NE3 <br></p>\n",
    "\n",
    "\n",
    "**Mapping.csv Format:**\n",
    "<p>Image_No HAP SAD SUR ANG DIS FEA PIC <br>\n",
    "1 2.87 2.52 2.10 1.97 1.97 2.06 KM-NE1 <br>\n",
    "2 2.87 2.42 1.58 1.84 1.77 1.77 KM-NE2 <br>\n",
    "3 2.50 2.10 1.70 1.50 1.73 1.53 KM-NE3 <br></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Universal_Label_Mapping = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad', 5:'Surprise', 6:'Neutral', 7:'Contempt'}\n",
    "Universal_Label_Mapping_Inverse = {v: k for k, v in Universal_Label_Mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(dataset, split_name, image_dir, base_dir):\n",
    "    labels = []\n",
    "    for idx, (_, row) in enumerate(dataset.iterrows()):\n",
    "        try:\n",
    "            # Process image\n",
    "            img_path = os.path.join(image_dir, row['filename'])\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            # Create new filename\n",
    "            new_filename = f\"{split_name}_{idx}_{row['label']}.png\"\n",
    "            save_path = os.path.join(base_dir, split_name, new_filename)\n",
    "            img.save(save_path)\n",
    "            \n",
    "            # Record label\n",
    "            labels.append({'filename': new_filename, 'label': Universal_Label_Mapping_Inverse[row['label']]})\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {row['filename']}: {str(e)}\")\n",
    "    \n",
    "    # Save labels CSV with numerical sorting\n",
    "    if labels:\n",
    "        labels_df = pd.DataFrame(labels)\n",
    "        labels_df.to_csv(os.path.join(base_dir, split_name, 'labels.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images_to_label_subdirectories(base_dir):\n",
    "    \"\"\"\n",
    "    For each subdirectory (test, train, validation) in base_dir,\n",
    "    copy images into subdirectories based on their label, extracted from the filename.\n",
    "    \n",
    "    Expected filename format: {usecase}_{index}_{label}.{ext}\n",
    "    \"\"\"\n",
    "    # Define the usage folders.\n",
    "    usage_dirs = ['train', 'test', 'validation']\n",
    "    \n",
    "    for usage in usage_dirs:\n",
    "        usage_path = os.path.join(base_dir, usage)\n",
    "        if not os.path.isdir(usage_path):\n",
    "            print(f\"Directory {usage_path} does not exist. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Process each file in the usage folder.\n",
    "        for filename in os.listdir(usage_path):\n",
    "            file_path = os.path.join(usage_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                # Parse the filename. We expect at least 3 parts separated by '_'\n",
    "                parts = filename.split('_')\n",
    "                if len(parts) < 3:\n",
    "                    print(f\"Filename {filename} does not match expected format. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # The label is assumed to be the last part, with the file extension removed.\n",
    "                label_with_ext = parts[-1]\n",
    "                label, _ = os.path.splitext(label_with_ext)\n",
    "                label = str(Universal_Label_Mapping_Inverse.get(label, None))\n",
    "                \n",
    "                # Create the label subdirectory if it doesn't exist.\n",
    "                label_dir = os.path.join(usage_path, label)\n",
    "                os.makedirs(label_dir, exist_ok=True)\n",
    "                \n",
    "                # Copy the image into the label subdirectory.\n",
    "                destination_file_path = os.path.join(label_dir, filename)\n",
    "                shutil.copy2(file_path, destination_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14848\\819462139.py:15: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(image_dir, mapping_file), delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing KM.SA4.12.tiff: [Errno 2] No such file or directory: 'JAFFE\\\\KM.SA4.12.tiff'\n",
      "Error processing NM.DI2.108.tiff: [Errno 2] No such file or directory: 'JAFFE\\\\NM.DI2.108.tiff'\n",
      "Error processing KM.DI2.21.tiff: [Errno 2] No such file or directory: 'JAFFE\\\\KM.DI2.21.tiff'\n",
      "Error processing TM.HA4.183.tiff: [Errno 2] No such file or directory: 'JAFFE\\\\TM.HA4.183.tiff'\n",
      "Error processing KM.HA5.8.tiff: [Errno 2] No such file or directory: 'JAFFE\\\\KM.HA5.8.tiff'\n",
      "Error processing KR.HA3.76.tiff: [Errno 2] No such file or directory: 'JAFFE\\\\KR.HA3.76.tiff'\n",
      "Filename labels.csv does not match expected format. Skipping.\n",
      "Filename labels.csv does not match expected format. Skipping.\n",
      "Filename labels.csv does not match expected format. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "base_dir = \"JAFFE_Structured_Aligned\"\n",
    "image_dir = \"JAFFE\"\n",
    "mapping_file = \"mapping.csv\"\n",
    "seed = 42\n",
    "test_val_size = 0.4  # 40% for test+validation (will split to 20% each)\n",
    "\n",
    "# Create directory structure\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "for split in ['train', 'test', 'validation']:\n",
    "    os.makedirs(os.path.join(base_dir, split), exist_ok=True)\n",
    "\n",
    "# Load and process mapping data\n",
    "df = pd.read_csv(os.path.join(image_dir, mapping_file), delim_whitespace=True)\n",
    "emotion_columns = ['HAP', 'SAD', 'SUR', 'ANG', 'DIS', 'FEA']\n",
    "emotion_mapping = {\n",
    "    'HAP': 'Happy',\n",
    "    'SAD': 'Sad',\n",
    "    'SUR': 'Surprise',\n",
    "    'ANG': 'Angry',\n",
    "    'DIS': 'Disgust',\n",
    "    'FEA': 'Fear'\n",
    "}\n",
    "\n",
    "# Determine dominant emotion for each image\n",
    "df['label'] = df[emotion_columns].idxmax(axis=1).map(emotion_mapping)\n",
    "\n",
    "df['filename'] = df.apply(\n",
    "    lambda row: (\n",
    "        row['PIC'].replace('-', '.') + \n",
    "        '.' + \n",
    "        str(row['Image_No']) + \n",
    "        '.tiff'\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Split dataset with stratification\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=test_val_size,\n",
    "    stratify=df['label'],\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df['label'],\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Save all splits\n",
    "save_images(train_df, 'train', image_dir, base_dir)\n",
    "save_images(val_df, 'validation', image_dir, base_dir)\n",
    "save_images(test_df, 'test', image_dir, base_dir)\n",
    "\n",
    "copy_images_to_label_subdirectories(base_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
